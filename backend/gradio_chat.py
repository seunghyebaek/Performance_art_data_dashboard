import gradio as gr
import asyncio
import os
import json
from dotenv import load_dotenv
from backend.AzureServiceModule.ChatbotService import ChatbotService
import threading
import uvicorn

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ChatbotService ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
chatbot = ChatbotService(
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    endpoint=os.getenv("ENDPOINT_URL"),
    deployment=os.getenv("DEPLOYMENT_NAME"),
    search_key=os.getenv("SEARCH_KEY"),
    search_endpoint=os.getenv("SEARCH_ENDPOINT"),
    search_index=os.getenv("SEARCH_INDEX_NAME")
)

# ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë³€ìˆ˜
history = []

# ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸° í•¨ìˆ˜ë¡œ ë˜í•‘
def predict(message, chat_history):
    global history
    
    if not message.strip():
        return chat_history, "", ""
    
    # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰ì„ ìœ„í•œ ì´ë²¤íŠ¸ ë£¨í”„
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    # ì±—ë´‡ ì„œë¹„ìŠ¤ í˜¸ì¶œ
    result = loop.run_until_complete(chatbot.handle_user_input(message, history))
    
    # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
    history = result["chat_history"]
    
    # Gradio ì±—ë´‡ì— ì¶”ê°€í•  ë©”ì‹œì§€ ìƒì„±
    bot_message = result["response_text"]
    
    # ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ì¶”ê°€
    chat_history.append({"role": "user", "content": message})
    chat_history.append({"role": "assistant", "content": bot_message})
    
    # ìˆ˜ì§‘ëœ ë³€ìˆ˜ ì •ë³´ í‘œì‹œ
    collected_vars = json.dumps(result["structured_data"], ensure_ascii=False, indent=2)
    
    # ì‚¬ì´ë“œë°” ì •ë³´ ì—…ë°ì´íŠ¸
    sidebar_info = f"ğŸ” ë‹¨ê³„: {result['stage']}\nğŸ“ ì˜ë„: {result['intent']}\n\nğŸ’¾ ìˆ˜ì§‘ëœ ë³€ìˆ˜:\n{collected_vars}"
    
    return chat_history, sidebar_info, ""

# Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
with gr.Blocks() as demo:
    gr.Markdown("# ê³µì—° ê¸°íš ì±—ë´‡")
    
    with gr.Row():
        with gr.Column(scale=3):
            chatbot_component = gr.Chatbot(height=600, type="messages")
            
            # ê¸°ë³¸ í…ìŠ¤íŠ¸ë°•ìŠ¤
            msg = gr.Textbox(
                placeholder="ê³µì—°ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”...", 
                lines=1
            )
            
            with gr.Row():
                clear = gr.Button("ëŒ€í™” ì´ˆê¸°í™”")
                submit_btn = gr.Button("ì „ì†¡", variant="primary")
            
        with gr.Column(scale=1):
            sidebar = gr.Textbox(label="ê³µì—° ì •ë³´", lines=20, max_lines=30)
    
    # ë©”ì‹œì§€ ì „ì†¡ ì‹œ ì´ë²¤íŠ¸ ì—°ê²°
    msg.submit(predict, [msg, chatbot_component], [chatbot_component, sidebar, msg])
    submit_btn.click(predict, [msg, chatbot_component], [chatbot_component, sidebar, msg])
    
    # ì´ˆê¸°í™” ë²„íŠ¼ ì´ë²¤íŠ¸ ì—°ê²°
    def clear_chat():
        global history
        history = []
        return [], "ê³µì—° ì •ë³´ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
    
    clear.click(clear_chat, None, [chatbot_component, sidebar])

# FastAPI ì„œë²„ë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
def run_fastapi():
    try:
        from backend.demo import app
        uvicorn.run(app, host="127.0.0.1", port=8000)
    except Exception as e:
        print(f"FastAPI ì„œë²„ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")

# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    # FastAPI ì„œë²„ ì‹œì‘ (ì„ íƒ ì‚¬í•­)
    try:
        threading.Thread(target=run_fastapi, daemon=True).start()
        print("FastAPI ì„œë²„ê°€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except:
        print("FastAPI ì„œë²„ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ê±°ë‚˜ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # Gradio ì•± ì‹¤í–‰
    demo.launch()